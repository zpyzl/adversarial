D:\ProgramData\Anaconda3\envs\jd\python.exe C:/Users/zpyzl/PycharmProjects/Chinese-Text-Classification-Pytorch/run.py --model TextCNN_FGSM
0it [00:00, ?it/s]Loading data...
Vocab size: 4762
180000it [00:02, 82060.10it/s]
10000it [00:00, 74810.78it/s]
10000it [00:00, 82758.90it/s]
Time usage: 0:00:02
<bound method Module.parameters of Model(
  (embedding): Embedding(4762, 300)
  (convs): ModuleList(
    (0): Conv2d(1, 256, kernel_size=(2, 300), stride=(1, 1))
    (1): Conv2d(1, 256, kernel_size=(3, 300), stride=(1, 1))
    (2): Conv2d(1, 256, kernel_size=(4, 300), stride=(1, 1))
  )
  (dropout): Dropout(p=0.5, inplace=False)
  (fc): Linear(in_features=768, out_features=10, bias=True)
)>
Epoch [1/20]
Iter:      0,  Train Loss:   2.3,  Train Acc:  9.38%,  Val Loss:   2.6,  Val Acc: 10.13%,  Time: 0:00:08 *
Iter:    100,  Train Loss:  0.76,  Train Acc: 69.53%,  Val Loss:   0.7,  Val Acc: 78.28%,  Time: 0:00:51 *
Iter:    200,  Train Loss:  0.69,  Train Acc: 76.56%,  Val Loss:  0.55,  Val Acc: 83.16%,  Time: 0:01:35 *
Iter:    300,  Train Loss:  0.51,  Train Acc: 84.38%,  Val Loss:  0.49,  Val Acc: 84.79%,  Time: 0:02:18 *
Iter:    400,  Train Loss:  0.72,  Train Acc: 80.47%,  Val Loss:  0.47,  Val Acc: 85.57%,  Time: 0:03:00 *
Iter:    500,  Train Loss:  0.41,  Train Acc: 85.94%,  Val Loss:  0.44,  Val Acc: 86.08%,  Time: 0:03:42 *
Iter:    600,  Train Loss:  0.52,  Train Acc: 88.28%,  Val Loss:  0.43,  Val Acc: 86.77%,  Time: 0:04:24 *
Iter:    700,  Train Loss:  0.49,  Train Acc: 81.25%,  Val Loss:   0.4,  Val Acc: 87.70%,  Time: 0:05:06 *
Iter:    800,  Train Loss:  0.43,  Train Acc: 85.94%,  Val Loss:  0.39,  Val Acc: 88.02%,  Time: 0:05:51 *
Iter:    900,  Train Loss:  0.44,  Train Acc: 90.62%,  Val Loss:  0.38,  Val Acc: 88.41%,  Time: 0:06:35 *
Iter:   1000,  Train Loss:  0.32,  Train Acc: 90.62%,  Val Loss:  0.39,  Val Acc: 88.22%,  Time: 0:07:19
Iter:   1100,  Train Loss:  0.38,  Train Acc: 90.62%,  Val Loss:  0.38,  Val Acc: 88.31%,  Time: 0:08:01 *
Iter:   1200,  Train Loss:  0.41,  Train Acc: 85.94%,  Val Loss:  0.37,  Val Acc: 88.84%,  Time: 0:08:44 *
Iter:   1300,  Train Loss:  0.43,  Train Acc: 85.16%,  Val Loss:  0.36,  Val Acc: 89.02%,  Time: 0:09:26 *
Iter:   1400,  Train Loss:   0.5,  Train Acc: 82.81%,  Val Loss:  0.36,  Val Acc: 88.99%,  Time: 0:10:08 *
Epoch [2/20]
Iter:   1500,  Train Loss:  0.47,  Train Acc: 86.72%,  Val Loss:  0.36,  Val Acc: 89.03%,  Time: 0:10:51 *
Iter:   1600,  Train Loss:  0.31,  Train Acc: 92.97%,  Val Loss:  0.35,  Val Acc: 89.37%,  Time: 0:11:34 *
Iter:   1700,  Train Loss:  0.39,  Train Acc: 86.72%,  Val Loss:  0.35,  Val Acc: 89.47%,  Time: 0:12:20 *
Iter:   1800,  Train Loss:  0.35,  Train Acc: 89.84%,  Val Loss:  0.36,  Val Acc: 88.99%,  Time: 0:13:06
Iter:   1900,  Train Loss:  0.33,  Train Acc: 89.84%,  Val Loss:  0.34,  Val Acc: 89.55%,  Time: 0:13:50 *
Iter:   2000,  Train Loss:  0.39,  Train Acc: 85.94%,  Val Loss:  0.34,  Val Acc: 89.27%,  Time: 0:14:34
Iter:   2100,  Train Loss:  0.41,  Train Acc: 89.84%,  Val Loss:  0.35,  Val Acc: 89.32%,  Time: 0:15:20
Iter:   2200,  Train Loss:  0.34,  Train Acc: 88.28%,  Val Loss:  0.34,  Val Acc: 89.72%,  Time: 0:16:05 *
Iter:   2300,  Train Loss:  0.34,  Train Acc: 91.41%,  Val Loss:  0.34,  Val Acc: 89.54%,  Time: 0:16:49
Iter:   2400,  Train Loss:  0.23,  Train Acc: 92.97%,  Val Loss:  0.35,  Val Acc: 89.33%,  Time: 0:17:31
Iter:   2500,  Train Loss:  0.22,  Train Acc: 90.62%,  Val Loss:  0.34,  Val Acc: 89.54%,  Time: 0:18:14
Iter:   2600,  Train Loss:  0.34,  Train Acc: 89.84%,  Val Loss:  0.33,  Val Acc: 89.81%,  Time: 0:18:57 *
Iter:   2700,  Train Loss:  0.27,  Train Acc: 88.28%,  Val Loss:  0.33,  Val Acc: 89.96%,  Time: 0:19:39 *
Iter:   2800,  Train Loss:   0.4,  Train Acc: 87.50%,  Val Loss:  0.33,  Val Acc: 89.83%,  Time: 0:20:23
Epoch [3/20]
Iter:   2900,  Train Loss:  0.37,  Train Acc: 88.28%,  Val Loss:  0.33,  Val Acc: 89.66%,  Time: 0:21:09
Iter:   3000,  Train Loss:  0.22,  Train Acc: 92.97%,  Val Loss:  0.33,  Val Acc: 89.80%,  Time: 0:22:02
Iter:   3100,  Train Loss:  0.29,  Train Acc: 90.62%,  Val Loss:  0.34,  Val Acc: 89.51%,  Time: 0:22:51
Iter:   3200,  Train Loss:  0.41,  Train Acc: 89.06%,  Val Loss:  0.34,  Val Acc: 89.63%,  Time: 0:23:42
Iter:   3300,  Train Loss:  0.32,  Train Acc: 90.62%,  Val Loss:  0.32,  Val Acc: 90.29%,  Time: 0:24:33 *
Iter:   3400,  Train Loss:  0.33,  Train Acc: 85.94%,  Val Loss:  0.33,  Val Acc: 90.06%,  Time: 0:25:22
Iter:   3500,  Train Loss:  0.17,  Train Acc: 95.31%,  Val Loss:  0.33,  Val Acc: 89.72%,  Time: 0:26:11
Iter:   3600,  Train Loss:  0.16,  Train Acc: 93.75%,  Val Loss:  0.32,  Val Acc: 89.94%,  Time: 0:27:00
Iter:   3700,  Train Loss:  0.34,  Train Acc: 87.50%,  Val Loss:  0.33,  Val Acc: 89.92%,  Time: 0:27:49
Iter:   3800,  Train Loss:  0.31,  Train Acc: 89.06%,  Val Loss:  0.33,  Val Acc: 90.01%,  Time: 0:28:37
Iter:   3900,  Train Loss:  0.36,  Train Acc: 89.84%,  Val Loss:  0.33,  Val Acc: 90.05%,  Time: 0:29:25
Iter:   4000,  Train Loss:  0.23,  Train Acc: 92.97%,  Val Loss:  0.33,  Val Acc: 89.95%,  Time: 0:30:13
Iter:   4100,  Train Loss:  0.19,  Train Acc: 92.19%,  Val Loss:  0.33,  Val Acc: 90.18%,  Time: 0:31:02
Iter:   4200,  Train Loss:  0.28,  Train Acc: 90.62%,  Val Loss:  0.33,  Val Acc: 90.02%,  Time: 0:31:52
Epoch [4/20]
Iter:   4300,  Train Loss:  0.27,  Train Acc: 91.41%,  Val Loss:  0.33,  Val Acc: 90.15%,  Time: 0:32:40
No optimization for a long time, auto-stopping...
Test Loss:  0.31,  Test Acc: 90.56%
Precision, Recall and F1-Score...
               precision    recall  f1-score   support

      finance     0.9177    0.9030    0.9103      1000
       realty     0.9242    0.9270    0.9256      1000
       stocks     0.8830    0.8380    0.8599      1000
    education     0.9465    0.9550    0.9507      1000
      science     0.8175    0.8780    0.8467      1000
      society     0.8945    0.9070    0.9007      1000
     politics     0.9023    0.8680    0.8848      1000
       sports     0.9377    0.9630    0.9502      1000
         game     0.9338    0.8880    0.9103      1000
entertainment     0.9046    0.9290    0.9166      1000

     accuracy                         0.9056     10000
    macro avg     0.9062    0.9056    0.9056     10000
 weighted avg     0.9062    0.9056    0.9056     10000

Confusion Matrix...
[[903  11  39   3  11   9   8  10   2   4]
 [ 11 927  13   1  13  12   9   4   3   7]
 [ 45  24 838   3  47   3  27   4   3   6]
 [  1   2   1 955   7   8   9   4   1  12]
 [  4   5  24   8 878  16  16   4  28  17]
 [  6  20   2  16  11 907  17   1   4  16]
 [ 11   5  25  12  25  40 868   4   1   9]
 [  1   1   2   1   6   7   3 963   2  14]
 [  0   2   4   6  64   6   3  14 888  13]
 [  2   6   1   4  12   6   2  19  19 929]]
Time usage: 0:00:11

Process finished with exit code 0
