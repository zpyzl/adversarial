user10000613@jupyter-user10000613-2dserver4435:~/notespace/Chinese-Text-Classification-Pytorch$ python3 run.py --model TextCNN_free
Loading data...
Vocab size: 4762
180000it [00:02, 62017.56it/s]
10000it [00:00, 35165.76it/s]
10000it [00:00, 62614.54it/s]
Time usage: 0:00:03
<bound method Module.parameters of Model(
  (embedding): Embedding(4762, 300)
  (convs): ModuleList(
    (0): Conv2d(1, 256, kernel_size=(2, 300), stride=(1, 1))
    (1): Conv2d(1, 256, kernel_size=(3, 300), stride=(1, 1))
    (2): Conv2d(1, 256, kernel_size=(4, 300), stride=(1, 1))
  )
  (dropout): Dropout(p=0.5)
  (fc): Linear(in_features=768, out_features=10, bias=True)
)>
Epoch [1/20]
Iter:      0,  Train Loss:   1.5,  Train Acc: 63.28%,  Val Loss:   2.1,  Val Acc: 26.97%,  Time: 0:00:01 *
Iter:    100,  Train Loss:  0.17,  Train Acc: 97.66%,  Val Loss:  0.56,  Val Acc: 83.27%,  Time: 0:00:52 *
Iter:    200,  Train Loss:  0.16,  Train Acc: 95.31%,  Val Loss:  0.57,  Val Acc: 83.36%,  Time: 0:01:43
Iter:    300,  Train Loss:   0.1,  Train Acc: 97.66%,  Val Loss:   0.5,  Val Acc: 85.63%,  Time: 0:02:35 *
Iter:    400,  Train Loss:  0.16,  Train Acc: 95.31%,  Val Loss:  0.53,  Val Acc: 85.26%,  Time: 0:03:26
Iter:    500,  Train Loss: 0.079,  Train Acc: 100.00%,  Val Loss:  0.47,  Val Acc: 86.13%,  Time: 0:04:17 *
Iter:    600,  Train Loss:  0.12,  Train Acc: 97.66%,  Val Loss:   0.5,  Val Acc: 85.83%,  Time: 0:05:08
Iter:    700,  Train Loss:  0.14,  Train Acc: 96.09%,  Val Loss:  0.49,  Val Acc: 86.65%,  Time: 0:05:59
Iter:    800,  Train Loss:  0.17,  Train Acc: 95.31%,  Val Loss:  0.45,  Val Acc: 87.22%,  Time: 0:06:51 *
Iter:    900,  Train Loss:  0.11,  Train Acc: 96.88%,  Val Loss:  0.47,  Val Acc: 86.49%,  Time: 0:07:42
Iter:   1000,  Train Loss:  0.13,  Train Acc: 94.53%,  Val Loss:  0.47,  Val Acc: 87.49%,  Time: 0:08:33
Iter:   1100,  Train Loss:  0.11,  Train Acc: 96.88%,  Val Loss:  0.46,  Val Acc: 87.06%,  Time: 0:09:24
Iter:   1200,  Train Loss:  0.19,  Train Acc: 94.53%,  Val Loss:  0.46,  Val Acc: 87.03%,  Time: 0:10:15
Iter:   1300,  Train Loss:  0.12,  Train Acc: 96.88%,  Val Loss:  0.49,  Val Acc: 86.47%,  Time: 0:11:06
Iter:   1400,  Train Loss:  0.22,  Train Acc: 94.53%,  Val Loss:  0.46,  Val Acc: 87.30%,  Time: 0:11:57
Epoch [2/20]
Iter:   1500,  Train Loss:  0.22,  Train Acc: 92.97%,  Val Loss:  0.48,  Val Acc: 87.30%,  Time: 0:12:48
Iter:   1600,  Train Loss:  0.13,  Train Acc: 95.31%,  Val Loss:  0.48,  Val Acc: 87.26%,  Time: 0:13:39
Iter:   1700,  Train Loss:   0.2,  Train Acc: 92.97%,  Val Loss:  0.45,  Val Acc: 88.11%,  Time: 0:14:31 *
Iter:   1800,  Train Loss:   0.1,  Train Acc: 96.88%,  Val Loss:  0.46,  Val Acc: 87.86%,  Time: 0:15:22
Iter:   1900,  Train Loss:  0.12,  Train Acc: 95.31%,  Val Loss:  0.47,  Val Acc: 88.09%,  Time: 0:16:13
Iter:   2000,  Train Loss:   0.2,  Train Acc: 95.31%,  Val Loss:  0.46,  Val Acc: 88.03%,  Time: 0:17:04

Iter:   2100,  Train Loss:  0.12,  Train Acc: 97.66%,  Val Loss:  0.45,  Val Acc: 88.30%,  Time: 0:17:55
Iter:   2200,  Train Loss: 0.074,  Train Acc: 96.88%,  Val Loss:  0.48,  Val Acc: 88.08%,  Time: 0:18:46
Iter:   2300,  Train Loss:  0.19,  Train Acc: 95.31%,  Val Loss:  0.47,  Val Acc: 87.95%,  Time: 0:19:37
Iter:   2400,  Train Loss:  0.12,  Train Acc: 95.31%,  Val Loss:  0.48,  Val Acc: 87.83%,  Time: 0:20:28
Iter:   2500,  Train Loss: 0.085,  Train Acc: 96.88%,  Val Loss:  0.46,  Val Acc: 88.41%,  Time: 0:21:20
Iter:   2600,  Train Loss:   0.1,  Train Acc: 96.88%,  Val Loss:  0.47,  Val Acc: 87.66%,  Time: 0:22:11

Iter:   2700,  Train Loss: 0.099,  Train Acc: 97.66%,  Val Loss:  0.45,  Val Acc: 88.22%,  Time: 0:23:08 *
Iter:   2800,  Train Loss:  0.21,  Train Acc: 92.19%,  Val Loss:  0.46,  Val Acc: 88.26%,  Time: 0:24:56
Epoch [3/20]

Iter:   2900,  Train Loss:  0.13,  Train Acc: 95.31%,  Val Loss:  0.48,  Val Acc: 88.51%,  Time: 0:26:44
Iter:   3000,  Train Loss: 0.098,  Train Acc: 96.88%,  Val Loss:  0.48,  Val Acc: 88.04%,  Time: 0:28:34
Iter:   3100,  Train Loss:  0.13,  Train Acc: 95.31%,  Val Loss:  0.47,  Val Acc: 88.41%,  Time: 0:30:23
Iter:   3200,  Train Loss: 0.052,  Train Acc: 98.44%,  Val Loss:   0.5,  Val Acc: 88.13%,  Time: 0:32:11

Iter:   3300,  Train Loss:  0.12,  Train Acc: 96.09%,  Val Loss:  0.49,  Val Acc: 88.21%,  Time: 0:34:00
Iter:   3400,  Train Loss: 0.099,  Train Acc: 96.09%,  Val Loss:  0.49,  Val Acc: 88.64%,  Time: 0:35:49

Iter:   3500,  Train Loss: 0.099,  Train Acc: 96.88%,  Val Loss:   0.5,  Val Acc: 88.44%,  Time: 0:37:37
Iter:   3600,  Train Loss: 0.054,  Train Acc: 98.44%,  Val Loss:   0.5,  Val Acc: 88.45%,  Time: 0:39:26
Iter:   3700,  Train Loss:  0.13,  Train Acc: 96.09%,  Val Loss:  0.47,  Val Acc: 88.33%,  Time: 0:41:15
No optimization for a long time, auto-stopping...
Test Loss:  0.31,  Test Acc: 90.01%
Precision, Recall and F1-Score...
               precision    recall  f1-score   support

      finance     0.9115    0.8860    0.8986      1000
       realty     0.9028    0.9290    0.9157      1000
       stocks     0.8350    0.8400    0.8375      1000
    education     0.9481    0.9500    0.9491      1000
      science     0.8746    0.8370    0.8554      1000
      society     0.8991    0.8910    0.8950      1000
     politics     0.8574    0.8960    0.8763      1000
       sports     0.9328    0.9580    0.9452      1000
         game     0.9067    0.9130    0.9098      1000
entertainment     0.9346    0.9010    0.9175      1000

     accuracy                         0.9001     10000
    macro avg     0.9003    0.9001    0.9000     10000
 weighted avg     0.9003    0.9001    0.9000     10000

Confusion Matrix...
[[886  20  56   1   5   9  11   6   3   3]
 [ 13 929  18   0   5  12   8   6   4   5]
 [ 48  28 840   3  32   2  37   3   6   1]
 [  1   3   5 950   4   9  11   5   3   9]
 [  4   9  42   5 837  16  25   5  44  13]
 [  5  23   1  20   6 891  37   3   5   9]
 [  9   6  30  10  11  27 896   6   0   5]
 [  3   1   4   1   4   6   6 958   5  12]
 [  0   1   7   4  42   8   6  13 913   6]
 [  3   9   3   8  11  11   8  22  24 901]]