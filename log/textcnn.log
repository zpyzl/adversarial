D:\ProgramData\Anaconda3\envs\jd\python.exe C:/Users/zpyzl/PycharmProjects/Chinese-Text-Classification-Pytorch/run.py --model TextCNN
0it [00:00, ?it/s]Loading data...
Vocab size: 4762
180000it [00:02, 71708.17it/s]
10000it [00:00, 89489.18it/s]
10000it [00:00, 84971.68it/s]
Time usage: 0:00:03
<bound method Module.parameters of Model(
  (embedding): Embedding(4762, 300)
  (convs): ModuleList(
    (0): Conv2d(1, 256, kernel_size=(2, 300), stride=(1, 1))
    (1): Conv2d(1, 256, kernel_size=(3, 300), stride=(1, 1))
    (2): Conv2d(1, 256, kernel_size=(4, 300), stride=(1, 1))
  )
  (dropout): Dropout(p=0.5, inplace=False)
  (fc): Linear(in_features=768, out_features=10, bias=True)
)>
Epoch [1/20]
Iter:      0,  Train Loss:   2.3,  Train Acc: 12.50%,  Val Loss:   2.6,  Val Acc: 11.05%,  Time: 0:00:12 *
Iter:    100,  Train Loss:  0.73,  Train Acc: 74.22%,  Val Loss:  0.69,  Val Acc: 78.48%,  Time: 0:01:00 *
Iter:    200,  Train Loss:  0.69,  Train Acc: 78.91%,  Val Loss:  0.55,  Val Acc: 83.12%,  Time: 0:01:46 *
Iter:    300,  Train Loss:  0.48,  Train Acc: 82.81%,  Val Loss:  0.49,  Val Acc: 84.65%,  Time: 0:02:41 *
Iter:    400,  Train Loss:  0.67,  Train Acc: 78.91%,  Val Loss:  0.47,  Val Acc: 85.75%,  Time: 0:03:30 *
Iter:    500,  Train Loss:  0.35,  Train Acc: 89.06%,  Val Loss:  0.44,  Val Acc: 86.64%,  Time: 0:04:17 *
Iter:    600,  Train Loss:   0.5,  Train Acc: 86.72%,  Val Loss:  0.43,  Val Acc: 86.83%,  Time: 0:05:03 *
Iter:    700,  Train Loss:  0.47,  Train Acc: 82.03%,  Val Loss:   0.4,  Val Acc: 87.44%,  Time: 0:05:51 *
Iter:    800,  Train Loss:  0.44,  Train Acc: 85.94%,  Val Loss:  0.39,  Val Acc: 88.18%,  Time: 0:06:40 *
Iter:    900,  Train Loss:   0.4,  Train Acc: 88.28%,  Val Loss:  0.38,  Val Acc: 88.19%,  Time: 0:07:32 *
Iter:   1000,  Train Loss:  0.32,  Train Acc: 89.84%,  Val Loss:   0.4,  Val Acc: 87.73%,  Time: 0:08:17
Iter:   1100,  Train Loss:  0.38,  Train Acc: 91.41%,  Val Loss:  0.37,  Val Acc: 88.70%,  Time: 0:08:58 *
Iter:   1200,  Train Loss:  0.38,  Train Acc: 85.16%,  Val Loss:  0.37,  Val Acc: 88.98%,  Time: 0:09:39 *
Iter:   1300,  Train Loss:  0.48,  Train Acc: 82.81%,  Val Loss:  0.37,  Val Acc: 88.60%,  Time: 0:10:22 *
Iter:   1400,  Train Loss:  0.54,  Train Acc: 83.59%,  Val Loss:  0.36,  Val Acc: 88.85%,  Time: 0:11:06 *
Epoch [2/20]
Iter:   1500,  Train Loss:  0.42,  Train Acc: 87.50%,  Val Loss:  0.35,  Val Acc: 89.05%,  Time: 0:11:47 *
Iter:   1600,  Train Loss:  0.27,  Train Acc: 91.41%,  Val Loss:  0.35,  Val Acc: 89.06%,  Time: 0:12:29
Iter:   1700,  Train Loss:  0.44,  Train Acc: 86.72%,  Val Loss:  0.34,  Val Acc: 89.38%,  Time: 0:13:12 *
Iter:   1800,  Train Loss:  0.35,  Train Acc: 88.28%,  Val Loss:  0.36,  Val Acc: 88.82%,  Time: 0:13:53
Iter:   1900,  Train Loss:  0.43,  Train Acc: 87.50%,  Val Loss:  0.34,  Val Acc: 89.47%,  Time: 0:14:34 *
Iter:   2000,  Train Loss:  0.34,  Train Acc: 86.72%,  Val Loss:  0.34,  Val Acc: 89.66%,  Time: 0:15:19 *
Iter:   2100,  Train Loss:  0.36,  Train Acc: 89.84%,  Val Loss:  0.34,  Val Acc: 89.52%,  Time: 0:16:01 *
Iter:   2200,  Train Loss:  0.33,  Train Acc: 91.41%,  Val Loss:  0.34,  Val Acc: 89.58%,  Time: 0:16:44 *
Iter:   2300,  Train Loss:   0.3,  Train Acc: 92.19%,  Val Loss:  0.33,  Val Acc: 89.66%,  Time: 0:17:27 *
Iter:   2400,  Train Loss:  0.25,  Train Acc: 91.41%,  Val Loss:  0.33,  Val Acc: 89.47%,  Time: 0:18:11 *
Iter:   2500,  Train Loss:  0.19,  Train Acc: 93.75%,  Val Loss:  0.34,  Val Acc: 89.73%,  Time: 0:18:55
Iter:   2600,  Train Loss:  0.42,  Train Acc: 89.06%,  Val Loss:  0.33,  Val Acc: 89.86%,  Time: 0:19:39 *
Iter:   2700,  Train Loss:  0.24,  Train Acc: 92.19%,  Val Loss:  0.33,  Val Acc: 89.68%,  Time: 0:20:24 *
Iter:   2800,  Train Loss:  0.44,  Train Acc: 85.16%,  Val Loss:  0.33,  Val Acc: 89.48%,  Time: 0:21:07
Epoch [3/20]
Iter:   2900,  Train Loss:  0.41,  Train Acc: 88.28%,  Val Loss:  0.33,  Val Acc: 89.98%,  Time: 0:21:51 *
Iter:   3000,  Train Loss:  0.25,  Train Acc: 91.41%,  Val Loss:  0.33,  Val Acc: 89.60%,  Time: 0:22:34
Iter:   3100,  Train Loss:  0.26,  Train Acc: 91.41%,  Val Loss:  0.34,  Val Acc: 89.58%,  Time: 0:23:16
Iter:   3200,  Train Loss:  0.41,  Train Acc: 90.62%,  Val Loss:  0.34,  Val Acc: 89.68%,  Time: 0:24:00
Iter:   3300,  Train Loss:  0.32,  Train Acc: 88.28%,  Val Loss:  0.32,  Val Acc: 90.13%,  Time: 0:24:46 *
Iter:   3400,  Train Loss:  0.33,  Train Acc: 89.06%,  Val Loss:  0.33,  Val Acc: 89.90%,  Time: 0:25:28
Iter:   3500,  Train Loss:  0.21,  Train Acc: 94.53%,  Val Loss:  0.32,  Val Acc: 89.85%,  Time: 0:26:11
Iter:   3600,  Train Loss:  0.16,  Train Acc: 96.09%,  Val Loss:  0.32,  Val Acc: 89.90%,  Time: 0:26:58
Iter:   3700,  Train Loss:  0.31,  Train Acc: 89.84%,  Val Loss:  0.33,  Val Acc: 89.95%,  Time: 0:27:43
Iter:   3800,  Train Loss:  0.26,  Train Acc: 88.28%,  Val Loss:  0.33,  Val Acc: 89.90%,  Time: 0:28:24
Iter:   3900,  Train Loss:  0.29,  Train Acc: 89.84%,  Val Loss:  0.33,  Val Acc: 89.82%,  Time: 0:29:06
Iter:   4000,  Train Loss:  0.26,  Train Acc: 92.97%,  Val Loss:  0.33,  Val Acc: 89.83%,  Time: 0:29:50
Iter:   4100,  Train Loss:  0.29,  Train Acc: 87.50%,  Val Loss:  0.32,  Val Acc: 90.08%,  Time: 0:30:33
Iter:   4200,  Train Loss:  0.32,  Train Acc: 89.84%,  Val Loss:  0.33,  Val Acc: 90.11%,  Time: 0:31:17
Epoch [4/20]
Iter:   4300,  Train Loss:  0.14,  Train Acc: 96.88%,  Val Loss:  0.33,  Val Acc: 90.00%,  Time: 0:31:59
No optimization for a long time, auto-stopping...
Test Loss:   0.3,  Test Acc: 90.71%
Precision, Recall and F1-Score...
               precision    recall  f1-score   support

      finance     0.9323    0.8810    0.9059      1000
       realty     0.9071    0.9370    0.9218      1000
       stocks     0.8579    0.8510    0.8544      1000
    education     0.9528    0.9490    0.9509      1000
      science     0.8410    0.8830    0.8615      1000
      society     0.9039    0.9120    0.9079      1000
     politics     0.9111    0.8610    0.8853      1000
       sports     0.9500    0.9510    0.9505      1000
         game     0.9198    0.9180    0.9189      1000
entertainment     0.9001    0.9280    0.9138      1000

     accuracy                         0.9071     10000
    macro avg     0.9076    0.9071    0.9071     10000
 weighted avg     0.9076    0.9071    0.9071     10000

Confusion Matrix...
[[881  22  56   3  12   6   7   7   3   3]
 [  9 937  15   1   5  11   5   3   2  12]
 [ 34  24 851   3  43   1  31   3   6   4]
 [  1   2   4 949   6  11   6   4   1  16]
 [  0   9  26   6 883  13  11   5  32  15]
 [  2  20   0  18  12 912  18   2   2  14]
 [ 11  10  29   9  23  38 861   4   1  14]
 [  2   2   5   2   6   8   1 951   6  17]
 [  3   1   5   2  48   3   2  10 918   8]
 [  2   6   1   3  12   6   3  12  27 928]]
Time usage: 0:00:09

Process finished with exit code 0
